{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,Dropout,Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 38s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 6s 1us/step\n"
     ]
    }
   ],
   "source": [
    "data = fashion_mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package tensorflow.keras.datasets in tensorflow.keras:\n",
      "\n",
      "NAME\n",
      "    tensorflow.keras.datasets - Public API for tf.keras.datasets namespace.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    boston_housing (package)\n",
      "    cifar10 (package)\n",
      "    cifar100 (package)\n",
      "    fashion_mnist (package)\n",
      "    imdb (package)\n",
      "    mnist (package)\n",
      "    reuters (package)\n",
      "\n",
      "FILE\n",
      "    c:\\users\\raghavendra\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\api\\_v2\\keras\\datasets\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = data # data available in the show code format`\n",
    "z = 0 # which later used for normalising it only one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['T-shirt/top', 'Trouser/pants', 'Pullover shirt', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'T-shirt/top',\n",
       " 1: 'Trouser/pants',\n",
       " 2: 'Pullover shirt',\n",
       " 3: 'Dress',\n",
       " 4: 'Coat',\n",
       " 5: 'Sandal',\n",
       " 6: 'Shirt',\n",
       " 7: 'Sneaker',\n",
       " 8: 'Bag',\n",
       " 9: 'Ankle boot'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict={}\n",
    "labels = '''T-shirt/top\n",
    "Trouser/pants\n",
    "Pullover shirt\n",
    "Dress\n",
    "Coat\n",
    "Sandal\n",
    "Shirt\n",
    "Sneaker\n",
    "Bag\n",
    "Ankle boot\n",
    "'''.split('\\n')[:-1]\n",
    "print(len(labels),labels)\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    labels_dict[i] = labels[i]\n",
    "    \n",
    "labels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions Which are Called Reccursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape():# checking the shape of train and test data sets\n",
    "    return x_train.shape,y_train.shape,x_test.shape,y_test.shape \n",
    "\n",
    "def max_min():\n",
    "    return x_train.max(),x_test.max(),x_train.min(),x_test.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Shape Of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))\n"
     ]
    }
   ],
   "source": [
    "print(shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Having a Glance Of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sneaker\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def glance(num):\n",
    "    \n",
    "    print(labels_dict[y_train[num]])\n",
    "    plt.imshow(x_train[num])\n",
    " \n",
    "glance(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking For min and max values in Data to  Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0, 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(max_min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: Don't execute this more than one time ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether data changed after normalising it: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if  z == 0:# if it is already executed then it means data is Normalised else not needed Normalise it again\n",
    "    x_train = x_train/ 255\n",
    "    x_test  = x_test / 255\n",
    "    z += 1\n",
    "\n",
    "print(\"Checking whether data changed after normalising it:\",end=\" \")\n",
    "x_train.max(),x_test.max(),x_train.min(),x_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshaping x_train and x_test and Categorising y data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((60000, 28, 28, 1), (60000,), (10000, 28, 28, 1), (10000,))\n",
      "(60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test  = x_test .reshape(-1,28,28,1)\n",
    "\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat  = to_categorical(y_test)\n",
    "\n",
    "print(shape())\n",
    "print(y_train_cat.shape,y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=256,kernel_size=(2,2),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters=512,kernel_size=(2,2),padding='same',activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=1024,kernel_size=(2,2),padding='same',activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=256,kernel_size=(2,2),padding='same',activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=(2,2),padding='same',activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 256)       1280      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 512)       524800    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 28, 28, 1024)      2098176   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 28, 28, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 128)       131200    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                3211296   \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 7,015,914\n",
      "Trainable params: 7,015,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early Stopping , is used to prevent from Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss',patience = 5, mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "60000/60000 [==============================] - 15702s 262ms/sample - loss: 0.9938 - accuracy: 0.6284 - val_loss: 0.4661 - val_accuracy: 0.8251\n",
      "Epoch 2/300\n",
      "24000/60000 [===========>..................] - ETA: 1:29:03 - loss: 0.7110 - accuracy: 0.7262"
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train,y=y_train_cat,callbacks=[es],batch_size=(64),epochs=300,validation_data=(x_test,y_test_cat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
